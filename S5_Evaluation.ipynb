{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from S1_CNN_Model import CNN_Model\n",
    "from S2_TimberDataset import TimberDataset, compile_image_df\n",
    "from S3_intermediateDataset import build_intermediate_dataset_if_not_exists, intermediate_dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, _ = compile_image_df(\"data/image/test\", split_at=1.0)\n",
    "\n",
    "def listdir_full(path: str) -> list[str]:\n",
    "    return [f\"{path}/{p}\" for p in os.listdir(path)]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((320,320)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_loader = DataLoader(TimberDataset(test_df, is_train=True,transform=transform),\n",
    "                            shuffle=True,\n",
    "                            batch_size=12)\n",
    "\n",
    "build_intermediate_dataset_if_not_exists(lambda x:x, \"test\", test_loader)\n",
    "test_loader = intermediate_dataset(\"test\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [09:00<00:00, 31.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ckpt/model_37.pt', 92.36111111111111), ('ckpt/model_36.pt', 91.39957264957265), ('ckpt/model.pt', 90.11752136752136), ('ckpt/model_23.pt', 90.11752136752136), ('ckpt/model_27.pt', 90.03739316239316), ('ckpt/model_19.pt', 89.95726495726495), ('ckpt/model_17.pt', 88.56837606837607), ('ckpt/model_16.pt', 87.79380341880342), ('ckpt/model_15.pt', 85.79059829059828), ('ckpt/model_13.pt', 85.04273504273505), ('ckpt/model_11.pt', 85.01602564102564), ('ckpt/model_14.pt', 84.58867521367522), ('ckpt/model_7.pt', 79.8076923076923), ('ckpt/model_6.pt', 79.27350427350427), ('ckpt/model_5.pt', 75.58760683760684), ('ckpt/model_4.pt', 70.86004273504274), ('ckpt/model_3.pt', 63.67521367521367)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model: CNN_Model):\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        with tqdm(test_loader, position=1, leave=False) as pb:\n",
    "            for images, labels in pb:\n",
    "                images = images.reshape(images.shape[1:])\n",
    "                labels = labels.reshape(labels.shape[1:])\n",
    "\n",
    "                x = model.forward(images)\n",
    "                _, predictions = torch.max(x,1)\n",
    "                \n",
    "                n_samples += labels.shape[0]\n",
    "                n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "                pb.set_description(f\"{n_correct}/{n_samples} correct predictions ({n_correct/n_samples*100 :.2f}%)\")\n",
    "\n",
    "    return n_correct/n_samples*100\n",
    "\n",
    "accuracies = [(model_path, evaluate_model(torch.load(model_path))) for model_path in tqdm(listdir_full(\"ckpt\"), position=0)]\n",
    "accuracies.sort(key = lambda x : x[1], reverse=True)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(TimberDataset(test_df, is_train=True,transform=transform),\n",
    "                            batch_size=12)\n",
    "\n",
    "build_intermediate_dataset_if_not_exists(lambda x:x, \"test_full\", test_loader)\n",
    "test_loader = intermediate_dataset(\"test_full\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [08:32<00:00, 30.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ckpt/model_37.pt', 97.11538461538461), ('ckpt/model_23.pt', 96.15384615384616), ('ckpt/model_36.pt', 96.15384615384616), ('ckpt/model_27.pt', 95.51282051282051), ('ckpt/model_19.pt', 95.1923076923077), ('ckpt/model.pt', 94.23076923076923), ('ckpt/model_17.pt', 94.23076923076923), ('ckpt/model_16.pt', 93.26923076923077), ('ckpt/model_15.pt', 92.94871794871796), ('ckpt/model_11.pt', 91.98717948717949), ('ckpt/model_13.pt', 91.34615384615384), ('ckpt/model_14.pt', 91.02564102564102), ('ckpt/model_7.pt', 88.78205128205127), ('ckpt/model_6.pt', 86.85897435897436), ('ckpt/model_5.pt', 82.05128205128204), ('ckpt/model_4.pt', 78.84615384615384), ('ckpt/model_3.pt', 70.83333333333334)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def full_images_evaluation(model: CNN_Model):\n",
    "    model.image_size = (320,320)\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        with tqdm(test_loader, position=1, leave = False) as pb:\n",
    "            for images, labels in pb:\n",
    "                images = images.reshape(images.shape[1:])\n",
    "                labels = labels.reshape(labels.shape[1:])\n",
    "\n",
    "                assert torch.all(labels == labels[0]).item()\n",
    "                label = labels[0]\n",
    "\n",
    "                x = model.forward(images)\n",
    "                _, preds = torch.max(x,1)\n",
    "                pred = torch.mode(preds,0).values\n",
    "                \n",
    "                n_samples += 1\n",
    "                n_correct += (pred == label).item()\n",
    "\n",
    "                pb.set_description(f\"{n_correct}/{n_samples} correct predictions ({n_correct/n_samples*100 :.2f}%)\")\n",
    "\n",
    "    return n_correct/n_samples*100\n",
    "\n",
    "full_accuracies = [(model_path, full_images_evaluation(torch.load(model_path)))\n",
    "                   for model_path in tqdm(listdir_full(\"ckpt\"), position=0)]\n",
    "full_accuracies.sort(key = lambda x : x[1], reverse=True)\n",
    "print(full_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x286ec807c00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
